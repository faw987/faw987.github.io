<!DOCTYPE html>


<!--WhatIsThis:

    html/js code to experiment with switching back-and-forth between open AI and ollama
    Early days, but does work to some extent

    I must say, adding comments with voice is pretty pleasurable
    And practical I might add
    So far, I don't think I've seen a single mistake other than OLLAMA which
    if you spell it out sort of works, but it gives you the new capitals OK

    -->


<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenAI, Ollama, Deepseek Interaction</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }

        #responseText {
            white-space: pre-wrap;
            overflow-y: auto;
            max-height: 300px;
            border: 1px solid #ccc;
            padding: 10px;
            background-color: #f9f9f9;
        }
    </style>
</head>
<body>
<h1>GPT-4 and Ollama Interaction</h1>
<form id="inputForm">
    <label>Choose Backend:</label><br>
    <input type="radio" id="backendOpenAI" name="backend1" value="openai" checked><label for="backendOpenAI">OpenAI
    Cloud</label><br>
    <input type="radio" id="backendOllama" name="backend1" value="ollama"><label for="backendOllama">Ollama
    Local</label><br><br>
    <input type="radio" id="backendDeepseek" name="backend1" value="DeepseekCloud"><label for="backendDeepseek">Deekseek
    Cloud</label><br><br>

    <label for="modelSelect">Choose Model:</label><br>
    <select id="modelSelect">
        <option value="gpt-4">GPT-4 (OpenAI)</option>
        <option value="gpt-3.5-turbo">GPT-3.5-Turbo (OpenAI)</option>
        <option value="qwen2">qwen2</option>
        <option value="deepseek-v2">Ollama deepseek-v2 (Local)</option>
        <option value="ollama-model-1">Ollama Model 1 (Local)</option>
        <option value="ollama-model-2">Ollama Model 2 (Local)</option>
        <option value="deepseek-chat">Deepseek Chat (Cloud)</option>
    </select><br><br>

    <label for="userInput">Enter your text:</label><br>
    <textarea id="userInput" rows="4" cols="50" placeholder="Type something..."></textarea><br><br>

    <button type="submit">Submit</button>
</form>

<!--<div id="response">-->
<!--    <h2>Response:</h2>-->
<!--    &lt;!&ndash; Increased max-height for more visible lines &ndash;&gt;-->
<!--    &lt;!&ndash;    <pre id="responseText" style="white-space: pre-wrap; overflow-y: auto; max-height: 400px; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;"></pre>&ndash;&gt;-->
<!--    <pre id="responseText"-->
<!--         style="white-space: pre-wrap; overflow-y: auto; max-height: 400px; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;"></pre>-->
<!--</div>-->

<div id="response">
    <h2>Response:</h2>
    <pre id="responseText"
         style="white-space: pre-wrap; overflow-y: auto; height: 600px; border: 1px solid #ccc; padding: 10px; background-color: #f9f9f9;"></pre>
</div>

<script src="js/util1.js"></script>

<script>

    async function processOpenai(selectedModel, modifiedPrompt) {
        // OpenAI Cloud API call
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                "Authorization": `Bearer ${calcResults()}` // Replace with your OpenAI API key
            },
            body: JSON.stringify({
                model: selectedModel,
                messages: [{role: 'user', content: modifiedPrompt}]
            })
        });
        console.log("RESPONSE:",JSON.stringify(response));
        return response;
    }

    async function processDeepseek(selectedModel, modifiedPrompt) {
        try {
            console.error("PJO:-) about to call");
            const response = await fetch('https://api.deepseek.com/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    "Authorization": `Bearer sk-e423f2c99cd543408f4f8966ab8a29be` // Replace with your OpenAI API key
                },
                body: JSON.stringify({
                    model: selectedModel,
                    messages: [{role: 'user', content: modifiedPrompt}]
                })
            });
        } catch (error) {
            // Log the error for debugging
            console.error("Error during streaming or fetch:", error);
        }
        ;
        return response;
    }


    async function processOllama(selectedModel, modifiedPrompt) {
        try {
            const response = await fetch(`http://localhost:11434/api/generate`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: selectedModel.replace("ollama-", ""), // Ensure model matches
                    prompt: modifiedPrompt
                })
            });

            // Check if the response object is valid and ok
            if (!response || !response.ok) {
                const errorText = response ? await response.text() : "No response received";
                throw new Error(`Ollama API Error: ${response?.status || "Unknown"} - ${errorText}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder("utf-8");
            responseText.textContent = ""; // Clear the field before appending new content

            while (true) {
                const {done, value} = await reader.read();
                if (done) break;

                // Decode and parse the JSON chunk
                const chunk = decoder.decode(value);
                const lines = chunk.split("\n").filter(line => line.trim() !== ""); // Handle multiple lines in a chunk
                for (const line of lines) {
                    try {
                        const jsonChunk = JSON.parse(line);
                        if (jsonChunk.response) {
                            // Append new text
                            responseText.textContent += jsonChunk.response;
                        }
                        if (jsonChunk.done) {
                            break; // Stop processing when done
                        }
                    } catch (parseError) {
                        console.error("Error parsing JSON chunk:", parseError, "Chunk:", line);
                    }
                }
            }

            // Final log for debugging
            console.log("Streaming completed successfully.");
        } catch (error) {
            // Log the error for debugging
            console.error("Error during streaming or fetch:", error);
        }
        return response;
    }

    // Handle form submission
    async function handleSubmit(event) {
        event.preventDefault();

        // Get form values
        const backend = document.querySelector('input[name="backend1"]:checked').value;
        const selectedModel = document.getElementById('modelSelect').value;
        const userInput = document.getElementById('userInput').value;
        const responseText = document.getElementById('responseText');

        if (!userInput.trim()) {
            responseText.textContent = "Please enter some text!";
            return;
        }

        // Build the modified prompt
        let modifiedPrompt = userInput;

        responseText.textContent = "Loading...";

        console.log("backend:", backend);

        let response = '';
        if (backend === "openai") {
            response = await processOpenai(selectedModel, modifiedPrompt);
            console.log("RESPONSE:",JSON.stringify(response));
        } else if (backend === "DeepseekCloud") {
            response = await processDeepseek(selectedModel, modifiedPrompt);
            console.log("RESPONSE:",JSON.stringify(response));

        } else if (backend === "ollama") {
            response = await processOllama(selectedModel, modifiedPrompt);
            console.log("RESPONSE:",JSON.stringify(response));

        };


        // const data = await response.json();
        const data = await response;

        // Log raw text response for debugging
        // const rawText = await response.text();
        console.log("data Raw Response:", data);

        const gptResponse = (() => {
            if (backend === "openai") {
                // OpenAI structure
                return data.choices[0].message.content;
            } else if (backend === "ollama") {
                // Assuming Ollama's response has a 'content' field
                return data.content;
            } else if (backend === "deepseek") {
                // DeepSeek response structure
                return data.choices[0]?.message?.content || "No response content available.";
            } else {
                return "Unknown backend or unsupported response format.";
            }
        })();

        responseText.textContent = gptResponse;

    }
    ;

    // Attach the form submit handler

    document.getElementById('inputForm').addEventListener('submit', handleSubmit);

</script>
</body>
</html>